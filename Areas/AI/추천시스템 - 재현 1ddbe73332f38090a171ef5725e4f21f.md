# 추천시스템?? - 재현

- Netflix : 대여되는 영화의 2/3가 추천으로부터 발생
- Google News : 38% 이상의 조회가 추천에 의해 발생
- Amazon : 판매의 35% 가 추천으로부터 발생
- Netflix Prize (~2009) Netflix에서 주관하는 경연대회로, 영화 선호도를 가장 잘 예측하는 협업 필터링 알고리즘에 수상 (US$1,000,000)

ㄷㄷ

추천 시스템의 분류

## 내용 기반(Content-based) 추천

말그대로 컨텐츠 자체의 내용을 기반으로 비슷한 컨텐츠를 추천한다.

간단하게 생각하면 텍스트 기반의 컨텐츠에선 TF-IDF와 같은 방식으로 추천한다
비교적 간단한 방법이지만 한계가 명확하다

그리고 실제로 사용하기 어렵다.

사전 지식도 있어야하고
개별 컨텐츠별 메타 데이터도 별로 없고
상품에서 뽑아내기도 어렵고

## 협업 필터링 (Collaborative Filtering)

그래서 많은 유저들로부터 모은 정보들을 기반으로 스스로 에측하는 방법이다.

예를 들어 A 유저가 한 이슈에 관해서 B 유저와 같은 의견을 갖는다면
다른 이슈에 대해서도 비슷한 의견을 가질 확률이 높을 것을 전제로 한다.

크게

- Memory-based
- Model-based
- Hybrid
로 구분된다

또

- User-Based
- Item-Based
로 나눠지는데
- 사용자 기반 : 비슷한 고객들이 ~한 제품을 구매했다.
- 아이템 기반 : ~ 상품을 구매한 고객들은 다음 상품도 구매했다.

|     | 공조  | 더 킹 | 라라랜드 | 컨택트 | 너의 이름은 |
| --- | --- | --- | ---- | --- | ------ |
| 재석  | 5   | 4   | 4    | 3   |        |
| 명수  | 1   | 0   | 1    |     | 4      |
| 하하  | 4   | 4   |      | 5   | 3      |
| 준하  |     | 2   | 1    | 4   | 3      |
| 세형  | 4   |     | 4    | 4   | 2      |
| 광희  | 4   | 2   | 3    |     | 1      |


### 사용자 기반

두 사용자가 얼마나 유사한 항목을 선호했는지를 기준으로 한다.
한 사용자가 선택한 항목들의 점수들을 백터로 나타낸다
보통  코사인 유사도, 피어슨 유사도를 사용한다.

예를들어
명수 점수가 (1, 0, 1, x, 4)
준하 점수가 (x, 2, 1, 4, 3)
이라면 공통적으로 평가한 항목들에 대해서 판단한다.

A=(0, 1, 4), B=(2, 1, 3)이고, 코사인 유사도는 다음과 같이 정의된다.

![](https://i.imgur.com/JHYevmk.png)

![](https://i.imgur.com/L6ucz1S.png)

요렇게 각각의 유사도를 구해서 weighted sum 같은걸로? 예측??

### 아이템 기반

공조, 라라랜드 유사도를 구한다면
이 둘을 모두 평가한 사용자는, 재석, 명수, 세형, 광희다. 각각 (5, 1, 4, 4)와 (4, 1, 4, 3)이다

![](https://i.imgur.com/3EnWNYA.png)

공조를 좋아하는 사람은 라라랜드를 좋아할 확률이 높다는 말로 풀이 될수 있고, 그 반대로도 해석할 수 있다.

문제?

(5, 5, 5, 5, 5, 5), (1, 1, 1, 1, 1, 1). 이 때, 이 둘간의 유사도는 1이다

그래서 피어슨 유사도, 혹은 약간의 보정 과정을 거친 코사인 유사도를 사용하기도 한다..

## 유저 추천에선??

- [https://www.slideshare.net/slideshow/261-52784785/52784785](https://www.slideshare.net/slideshow/261-52784785/52784785)

유저를 추천한다면
메모리 베이스 기반에 유저 기반이 적절해보임

- 비슷한 고객들이 ~한 제품을 구매했다.
가 해당 케이스에 적절해보임

~~다만 너무 정확한 추천은 좋지 않음.. 랜덤+신규+추천시스템 정도가 최선일듯??~~

아무튼 저 슬라이드를 참고해서

MinHash + LSH를 사용하는데

![](https://i.imgur.com/unwYjM1.png)

Jaccard Similarity를 사용

- 정확도를 어느정도 포기하고 속도를 챙긴 방식이라고 생각하면 쉬울듯?
- 0이 많은 데이터에서는 해당 부분을 고려준다.
sparse한 데이터에 적합한가..?
- sparse가 너무 심한 경우엔 유사도 계산이 힘들어 유사도 찾기가 힘들지도??? 유저별 좋아요 분포를 한번 봐야할듯??
- **어떤 랜덤 순열에서 가장 먼저 등장하는 원소가 같을 확률 = Jaccard 유사도**

### Minhash

- Jaccard Simility 유사도를 빠르게 근사하기 위한 방법

![](https://i.imgur.com/QQjM6Or.png)

![](https://i.imgur.com/9dU2g2y.png)

![](https://i.imgur.com/6fJdgSk.png)

따라서 MinHashing을 사용하여 희소성을 제거하고 유사성을 유지함으로써 공간복잡성 문제를 해결할 수 있다.

### LSH(Locality-Sensitive Hashing)

LSH는 Minhash를 통해 구한 signature matrix의 한 컬럼을 가지고 어떻게 비슷한 다른 컬럼을 찾을 수 있을지이다.

![](https://i.imgur.com/qMiI2KQ.png)

길이가 n인 signature matrix를 b등분 해서 b bands로
각 Band는 r의 행을 가짐

b * r = n

각 밴드는 k개의 버킷을 가지고 있고, 밴드별로 할당된 시그니처의 열을 k개의 버킷에 해싱

![](https://i.imgur.com/pkXM4Vr.png)

이때 b와 r을 결정해야 한다.

1. b가 커지면 similarity threshold가 낮다. 이는 FP가 높다는 것을 의미.
2. b가 작아지면 similarity threshold가 높다. 이는 FN가 높다는 것을 의미.

FP : False Positive = 비슷하지 않은데 비슷하다고 판단하는 오류
FN : False Negative = 비슷한데 비슷하지 않다고 판단하는 오류

위 설명을 참고하자면 n은 고정이기 때문에 b가 커지면 r은 작아진다.

알고리즘에서는 하나의 band에 들어있는 모든 row를 해시한 값이 일치하면 비슷한 문서라고 판단

그러므로 r이 낮을 수록 문서를 비슷하다고 판단할 확률이 높아진다고 볼 수 있음...

> 어렵다..
> 

### 슬라이드 이어서..

실제로는 Random permutation 만드는것도 리소스가 꽤 든다
universal hash 를 랜덤 생성해서 proxy로 사용??

- 어떠한 키 유니버스가 주어져도 충돌의 개수를 줄여서 가장 큰 chain 의 크기를 상수로 만드는 해쉬 함수

hash 되어 나온 값을 시그니처라하고 적당히 concate 시켜서 cluster id 삼아서 한다는데
Signature Matrix 말하는듯?? 문서의 핑거 프린트 같은 느낌

그담에 LSH의 Banding하는걸
적당히 concate 시키다..

```
# 클러스터 만들기
for 후보 in 모든 후보:
	그 호부의 모든 클릭 스트림 로딩
	로딩한것으로 MinHash Signature 생성
	Signature들을 concate해서 다량의 cluster id 생성
	후보들 해당 Cluster Id들에 집어넣기
for cluster in 만들어진 클러스터들:
	if length(클러스터) > threshold:
		클러스터의 멤버십 정보 저장

# 클러스터 정보로 추천하기
if 타겟 Item이 존재:
	타겟 Itemdml minhash 값을 가져옴
	Minhash 값을 Concate해서 Cluster id 리스트 작성
	통해 cluster 다 찾기
	for cluster in 타겟이 포함된 클러스터들:
		클러스터내 다른 item 로딩
		Item들의 클릭스트림 로딩
		기초로 pair 유사도 계산
	각 클러스터들로 부터 모은 유사도 top N개 추출
	적절히 소팅 후 추천

```

### 개선??

요건 느리다
minhash로 클러스팅, 추천하기
모두 Heavy I/O 가 잦음

- 

클러스터를 쓰면

- 장점: 후보 한정 - speed UP
- 단점: 후보 한정 - qualitiy Loss

I/O 문제는 왜 나오는가

상품과 유저의 부익부 빈익빈 때문에

그니까 서비스 기준으로 보면
스와이프 많이 하는 사람과 적게하는 사람이 존재하고
스와이프를 많이 받는 사람과 적게 받는 사람이 존재함

인기 있는 유저가 있다면
비교대상으로 자주 등장
ㄴ 엄청 긴 클릭스트림
ㄴ 로딩하는데 오래걸림
ㄴ 공간 모잘라서 캐싱도 날라감
ㄴ 각종 page out..
ㄴ 퍼모먼스 저하

인기 아이템(유저)의 클릭스트림 길이를 어케 해야함

클릭 스트림 원본 말고 대체본
대체본끼리 비교해 유사도를 알아야함
ㄴ minhash

hash function 수 n만큼 signatrue 생성?
ㄴ 모두 같은 길이를 가짐

signature이 겹치는 sig의 비율이 곧 jaccard

signature의 길이가 어느정도 되어야하는가?
100개 정도면 근사한다?

- 요건 테스트 필요할듯??

63P 까지 읽음..

- [https://www.slideshare.net/slideshow/261-52784785/52784785](https://www.slideshare.net/slideshow/261-52784785/52784785)
- [https://criling.tistory.com/61](https://criling.tistory.com/61)
- [https://trivia-starage.tistory.com/192](https://trivia-starage.tistory.com/192)
- [https://medium.com/h-document/자카드-거리-jaccard-distance-e5b246603775](https://medium.com/h-document/%EC%9E%90%EC%B9%B4%EB%93%9C-%EA%B1%B0%EB%A6%AC-jaccard-distance-e5b246603775)
- [https://coding-wonderland.tistory.com/14](https://coding-wonderland.tistory.com/14)